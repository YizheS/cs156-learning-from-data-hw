{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from hw6_dataload import LFD_Data\n",
    "from hw6_nlt import LinRegNLT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 7\n",
    "## Validation\n",
    "**Given :** Linear Regression with nonlinear transformation.\n",
    "\n",
    "\n",
    "&Phi;(x) = (1, x<sub>1</sub>, x<sub>2</sub>, x<sub>1</sub><sup>, 2</sup>, x<sub>2</sub><sup>2</sup>, x<sub>1</sub>x<sub>2</sub>, |x<sub>1</sub> - x<sub>2</sub>|, |x<sub>1</sub> + x<sub>2</sub>|)\n",
    "\n",
    "\n",
    "As this transformation is the same as the one from HW6 (as well as the datasets), I will reuse the classes from the last homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LinReg with NLT using the first 25 examples for training (last 10 for validation) ===\n",
      "k = 3 :\n",
      "E_valid: 0.300000, E_out: 0.420000\n",
      "k = 4 :\n",
      "E_valid: 0.500000, E_out: 0.416000\n",
      "k = 5 :\n",
      "E_valid: 0.200000, E_out: 0.188000\n",
      "k = 6 :\n",
      "E_valid: 0.000000, E_out: 0.084000\n",
      "k = 7 :\n",
      "E_valid: 0.100000, E_out: 0.072000\n",
      "\n",
      "=== LinReg with NLT using the last 10 examples for training (first 25 for validation) ===\n",
      "k = 3 :\n",
      "E_valid: 0.280000, E_out: 0.396000\n",
      "k = 4 :\n",
      "E_valid: 0.360000, E_out: 0.388000\n",
      "k = 5 :\n",
      "E_valid: 0.200000, E_out: 0.284000\n",
      "k = 6 :\n",
      "E_valid: 0.080000, E_out: 0.192000\n",
      "k = 7 :\n",
      "E_valid: 0.120000, E_out: 0.196000\n"
     ]
    }
   ],
   "source": [
    "rwd_train = \"hw6_train.dta\"\n",
    "rwd_test = \"hw6_test.dta\"\n",
    "l_reg = math.pow(10.0, -3) #actually, doesn't use regularization but just copying over from last hw anyways.\n",
    "\n",
    "# load data from external files and init\n",
    "rwd_data = LFD_Data(rwd_train, rwd_test)\n",
    "rwd_algo = LinRegNLT2(rwd_data.dim, 7, l_reg)\n",
    "\n",
    "#editing from hw6 to make more flexible\n",
    "def rwd_print_error(algo,valid_X, valid_Y, out_X, out_Y):\n",
    "    #ein = algo.calc_error(in_X, in_Y)\n",
    "    e_valid = algo.calc_error(valid_X, valid_Y)\n",
    "    eout = algo.calc_error(out_X, out_Y)\n",
    "    print(\"E_valid: %f, E_out: %f\" % (e_valid, eout))\n",
    "    \n",
    "print(\"=== LinReg with NLT using the first 25 examples for training (last 10 for validation) ===\")\n",
    "my_k = np.arange(3,8) #up through which cols (0-idx to use for training)\n",
    "#train without regularization\n",
    "for k in my_k:\n",
    "    print(\"k = %d :\" % k)\n",
    "    rwd_algo.set_k(k)\n",
    "    rwd_algo.train(rwd_data.train_X[:25,:], rwd_data.train_Y[:25])\n",
    "    rwd_print_error(rwd_algo, rwd_data.train_X[25:,:], rwd_data.train_Y[25:], rwd_data.test_X, rwd_data.test_Y)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=== LinReg with NLT using the last 10 examples for training (first 25 for validation) ===\")\n",
    "my_k = np.arange(3,8) #up through which cols (0-idx to use for training)\n",
    "#train without regularization\n",
    "for k in my_k:\n",
    "    print(\"k = %d :\" % k)\n",
    "    rwd_algo.set_k(k)\n",
    "    rwd_algo.train(rwd_data.train_X[25:,:], rwd_data.train_Y[25:])\n",
    "    rwd_print_error(rwd_algo, rwd_data.train_X[:25,:], rwd_data.train_Y[:25], rwd_data.test_X, rwd_data.test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Bias\n",
    "\n",
    "**Want :** Expected values of e, e1, and e2 given that e1 and e2 are independent, uniformly-distributed random variables over [0,1] and e = min(e1, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected values: \n",
      "e: 0.333768\n",
      "e1: 0.501344\n",
      "e2: 0.499188\n"
     ]
    }
   ],
   "source": [
    "vb_n = 100000 #number of random numbers to generate for each e1 and e2\n",
    "e1 = np.random.uniform(0,1, vb_n)\n",
    "e2 = np.random.uniform(0,1, vb_n)\n",
    "e = np.minimum(e1, e2)\n",
    "\n",
    "ev_e1 = np.average(e1)\n",
    "ev_e2 = np.average(e2)\n",
    "ev_e = np.average(e)\n",
    "\n",
    "print(\"Expected values: \")\n",
    "print(\"e: %f\" % ev_e)\n",
    "print(\"e1: %f\" % ev_e1)\n",
    "print(\"e2: %f\" % ev_e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "**Given :**\n",
    "- data points (x,y): (-1,0), (&rho;, 1), (1,0) &SuchThat; &rho; &ge; 0\n",
    "- choice between two models: constant {h<sub>0</sub>(x) = b}, linear {h<sub>1</sub>(x) = ax + b}\n",
    "\n",
    "**Want :** value of &rho; that ties squared error measures for both models using leave-one-out cross-validation\n",
    "\n",
    "**Note :** N = 3\n",
    "- E<sub>cv</sub> = (1/N) &sum;(n=1;N){e<sub>n</sub>}\n",
    "- e<sub>n</sub> = sqrt((h(x) - y)<sup>2</sup>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

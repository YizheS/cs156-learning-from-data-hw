{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hw8_dataload import LFD_Data2\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 8\n",
    "## Primal vs Dual Problem\n",
    "\n",
    "- The SVM **primal** problem minimizes 0.5w<sup>T</sup>w subject to y<sub>n</sub>(w<sup>T</sup>x<sub>n</sub>+b)&ge;1 for n = 1,2,...,N\n",
    "- Since w is a d-dimensional vector (corresponding to the dimension of x) and we can also vary b, the primal problem involves a quadratic programming problem with **d+1 variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernels\n",
    "\n",
    "- Implementing polynimal kernels with a soft-margin SVM using the given data set of handwritten digits from the US Postal Service Zip Code data set with extracted features digit, intensity, and symmetry. \n",
    "- The polynomial kernel K(x<sub>n</sub>, x<sub>m</sub>) = (1+x<sub>n</sub><sup>T</sup>x<sub>m</sub>)<sup>Q</sup>\n",
    "- Training **two** types of binary classifiers:\n",
    "    - one-vs-one (one digit class is +1, another is -1, rest are ignored)\n",
    "    - one-vs-all (one digit class is +1, everything else is -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw8_train = \"hw8_train.dta\"\n",
    "hw8_test = \"hw8_test.dta\"\n",
    "hw8_C = 0.01\n",
    "hw8_Q = 2\n",
    "hw8_data = LFD_Data2(hw8_train, hw8_test)\n",
    "\n",
    "my_svm = svm.SVC(C = 0.01, kernel = 'poly',degree = 2, coef0 = 1.0, gamma = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-vs-all binary classifier in-sample error: 0.105884\n",
      "1-vs-all binary classifier in-sample error: 0.014401\n",
      "2-vs-all binary classifier in-sample error: 0.100261\n",
      "3-vs-all binary classifier in-sample error: 0.090248\n",
      "4-vs-all binary classifier in-sample error: 0.089425\n",
      "5-vs-all binary classifier in-sample error: 0.076258\n",
      "6-vs-all binary classifier in-sample error: 0.091071\n",
      "7-vs-all binary classifier in-sample error: 0.088465\n",
      "8-vs-all binary classifier in-sample error: 0.074338\n",
      "9-vs-all binary classifier in-sample error: 0.088328\n",
      "Diff in number of sv's between odd and even: 2071\n"
     ]
    }
   ],
   "source": [
    "alphas_odd = np.array([])\n",
    "alphas_even = np.array([])\n",
    "\n",
    "for cur_num in range(10):\n",
    "    #cur_num-vs-all\n",
    "    hw8_data.set_filter([cur_num])\n",
    "    cur_X = hw8_data.get_X(\"train\")\n",
    "    cur_Y = hw8_data.get_Y(\"train\")\n",
    "    my_svm.fit(cur_X, cur_Y)\n",
    "    cur_score = my_svm.score(cur_X, cur_Y)\n",
    "    cur_numalphas = my_svm.n_support_\n",
    "    cur_asum = np.array(cur_numalphas).sum()\n",
    "    print(\"%d-vs-all binary classifier in-sample error: %f\" % (cur_num, (1.0 - cur_score)))\n",
    "    if cur_num % 2 == 0:\n",
    "        alphas_even = np.concatenate((alphas_even, [cur_asum]))\n",
    "    else:\n",
    "        alphas_odd = np.concatenate((alphas_odd, [cur_asum]))\n",
    "    \n",
    "    \n",
    "aodd_sum = np.sum(alphas_odd)\n",
    "aeven_sum = np.sum(alphas_even)\n",
    "a_diff = abs(aodd_sum - aeven_sum)\n",
    "print(\"Diff in number of sv's between odd and even: %d\" % a_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With C = 0.01, Q=2 and with a n-vs-all classifier, it turns out that 0 out of all the evens has the highest in-sample error and 1 out of all the odds has the lowest in-sample error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 2) (1561,) (424, 2) (424,)\n"
     ]
    }
   ],
   "source": [
    "#loading 1-vs-5 data\n",
    "\n",
    "hw8_data.set_filter([1,5])\n",
    "x_1v5_train = hw8_data.get_X(\"train\")\n",
    "y_1v5_train= hw8_data.get_Y(\"train\")\n",
    "x_1v5_test = hw8_data.get_X(\"test\")\n",
    "y_1v5_test= hw8_data.get_Y(\"test\")\n",
    "\n",
    "print(x_1v5_train.shape, y_1v5_train.shape, x_1v5_test.shape, y_1v5_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ For polynomial kernels of degree Q = 2 ~~~\n",
      "C = 0.000100 | E_in = 0.008969, E_out = 0.016509, num_sv = 236\n",
      "C = 0.001000 | E_in = 0.004484, E_out = 0.016509, num_sv = 76\n",
      "C = 0.010000 | E_in = 0.004484, E_out = 0.018868, num_sv = 34\n",
      "C = 0.100000 | E_in = 0.004484, E_out = 0.018868, num_sv = 24\n",
      "C = 1.000000 | E_in = 0.003203, E_out = 0.018868, num_sv = 24\n",
      "\n",
      "~~~ For polynomial kernels of degree Q = 5 ~~~\n",
      "C = 0.000100 | E_in = 0.004484, E_out = 0.018868, num_sv = 26\n",
      "C = 0.001000 | E_in = 0.004484, E_out = 0.021226, num_sv = 25\n",
      "C = 0.010000 | E_in = 0.003844, E_out = 0.021226, num_sv = 23\n",
      "C = 0.100000 | E_in = 0.003203, E_out = 0.018868, num_sv = 25\n",
      "C = 1.000000 | E_in = 0.003203, E_out = 0.021226, num_sv = 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pk_Q = [2,5]\n",
    "pk_C = [pow(10, -x) for x in reversed(range(5))]\n",
    "\n",
    "for Q in pk_Q:\n",
    "    my_svm.degree = Q\n",
    "    print(\"~~~ For polynomial kernels of degree Q = %d ~~~\" % Q)\n",
    "    for C in pk_C:\n",
    "        my_svm.C = C\n",
    "        my_svm.fit(x_1v5_train, y_1v5_train)\n",
    "        cur_ein = 1.0 - my_svm.score(x_1v5_train, y_1v5_train)\n",
    "        cur_eout = 1.0 - my_svm.score(x_1v5_test, y_1v5_test)\n",
    "        cur_numalphas = my_svm.n_support_\n",
    "        cur_asum = np.array(cur_numalphas).sum()\n",
    "        print(\"C = %f | E_in = %f, E_out = %f, num_sv = %d\" % (C, cur_ein, cur_eout, cur_asum))\n",
    "    print(\"\")\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

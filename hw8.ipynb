{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hw8_dataload import LFD_Data2\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 8\n",
    "## Primal vs Dual Problem\n",
    "\n",
    "- The SVM **primal** problem minimizes 0.5w<sup>T</sup>w subject to y<sub>n</sub>(w<sup>T</sup>x<sub>n</sub>+b)&ge;1 for n = 1,2,...,N\n",
    "- Since w is a d-dimensional vector (corresponding to the dimension of x) and we can also vary b, the primal problem involves a quadratic programming problem with **d+1 variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernels\n",
    "\n",
    "- Implementing polynimal kernels with a soft-margin SVM using the given data set of handwritten digits from the US Postal Service Zip Code data set with extracted features digit, intensity, and symmetry. \n",
    "- The polynomial kernel K(x<sub>n</sub>, x<sub>m</sub>) = (1+x<sub>n</sub><sup>T</sup>x<sub>m</sub>)<sup>Q</sup>\n",
    "- Training **two** types of binary classifiers:\n",
    "    - one-vs-one (one digit class is +1, another is -1, rest are ignored)\n",
    "    - one-vs-all (one digit class is +1, everything else is -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-vs-all binary classifier score: 0.894116\n",
      "1-vs-all binary classifier score: 0.985599\n",
      "2-vs-all binary classifier score: 0.899739\n",
      "3-vs-all binary classifier score: 0.909752\n",
      "4-vs-all binary classifier score: 0.910575\n",
      "5-vs-all binary classifier score: 0.923742\n",
      "6-vs-all binary classifier score: 0.908929\n",
      "7-vs-all binary classifier score: 0.911535\n",
      "8-vs-all binary classifier score: 0.925662\n",
      "9-vs-all binary classifier score: 0.911672\n",
      "Diff in number of sv's between odd and even: 2071\n"
     ]
    }
   ],
   "source": [
    "hw8_train = \"hw8_train.dta\"\n",
    "hw8_test = \"hw8_test.dta\"\n",
    "hw8_C = 0.01\n",
    "hw8_Q = 2\n",
    "hw8_data = LFD_Data2(hw8_train, hw8_test)\n",
    "\n",
    "alphas_odd = np.array([])\n",
    "alphas_even = np.array([])\n",
    "\n",
    "my_svm = svm.SVC(C = 0.01, kernel = 'poly',degree = 2, coef0 = 1.0, gamma = 1.0)\n",
    "for cur_num in range(10):\n",
    "    #cur_num-vs-all\n",
    "    hw8_data.set_filter([cur_num])\n",
    "    cur_X = hw8_data.get_X(\"train\")\n",
    "    cur_Y = hw8_data.get_Y(\"train\")\n",
    "    my_svm.fit(cur_X, cur_Y)\n",
    "    cur_score = my_svm.score(cur_X, cur_Y)\n",
    "    cur_numalphas = my_svm.n_support_\n",
    "    cur_asum = np.array(cur_numalphas).sum()\n",
    "    print(\"%d-vs-all binary classifier score: %f\" % (cur_num, cur_score))\n",
    "    if cur_num % 2 == 0:\n",
    "        alphas_even = np.concatenate((alphas_even, [cur_asum]))\n",
    "    else:\n",
    "        alphas_odd = np.concatenate((alphas_odd, [cur_asum]))\n",
    "    \n",
    "    \n",
    "aodd_sum = np.sum(alphas_odd)\n",
    "aeven_sum = np.sum(alphas_even)\n",
    "a_diff = abs(aodd_sum - aeven_sum)\n",
    "print(\"Diff in number of sv's between odd and even: %d\" % a_diff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
